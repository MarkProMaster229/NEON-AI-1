# NEON-AI-1 — Минимальный чат-бот на PyTorch

NEON-AI-1 — это базовый чат-бот, построенный на основе LSTM-модели в PyTorch. Он обучается на парах текста "Пользователь: ... / Бот: ..." из текстового файла `data.txt`. Проект демонстрирует простой пайплайн: от загрузки данных и токенизации до обучения модели и генерации ответов.

## Основные возможности

- Загрузка и обработка диалогов из текстового файла.
- Токенизация и создание словаря.
- Обучение LSTM-модели для генерации ответов.
- Сохранение и загрузка весов модели.
- Генерация ответов на пользовательские вопросы.

## Зависимости

- **Python**: 3.7 или выше
- **PyTorch**: `torch` (установите последнюю версию)
- **CUDA** (опционально): для обучения на GPU

Установите зависимости с помощью pip:

```bash
pip install torch
```

## Формат входных данных

Файл `data.txt` должен быть в следующем формате:

```
Пользователь: Привет
Бот: Привет! Чем могу помочь?
Пользователь: Что ты умеешь?
Бот: Я умею отвечать на простые вопросы.
```

- Диалоги чередуются: вопрос → ответ → вопрос → ответ.
- Файл должен находиться в корне проекта.

## Установка и запуск

1. **Склонируйте репозиторий**:

   ```bash
   git clone <URL_репозитория>
   cd NEON-AI-1
   ```

2. **Подготовьте данные**:

   - Убедитесь, что файл `data.txt` находится в корне проекта и содержит пары "Пользователь/Бот".
   - Укажите путь к `data.txt` в переменной `file_path` в файле `chatbot.py`:

     ```python
     file_path = r"C:\путь\к\файлу\NEON-AI-1\data.txt"
     ```

3. **Запустите скрипт**:

   ```bash
   python chatbot.py
   ```

### Что делает скрипт?

- Загружает и обрабатывает диалоги из `data.txt`.
- Создает словарь слов и токенизирует вопросы/ответы.
- Паддит последовательности для обучения.
- Создает и обучает LSTM-модель (если веса не сохранены).
- Сохраняет веса модели в `Chatbot_model.pth`.
- Генерирует тестовый ответ на фразу: **"Что ты умеешь?"**.

## Архитектура модели

- **Слой эмбеддингов**: преобразует слова в векторные представления.
- **LSTM**: обрабатывает последовательности для учета контекста.
- **Линейный слой**: выводит распределение вероятностей по словарю.

## Пример вывода

```
Пользователь: Что ты умеешь?
Бот: Я умею отвечать на простые вопросы.
```

## Примечания

- Веса модели сохраняются в `Chatbot_model.pth`. Если файл существует, модель не переобучается.
- Неизвестные слова заменяются на `<UNK>`.
- Текст приводится к нижнему регистру, знаки препинания удаляются.
- Размер словаря увеличен на 1 (0 — для паддинга).
- Словарь (`word_to_index`, `index_to_word`) пересоздается при каждом запуске.

## Потенциальные улучшения

- Добавить нормализацию текста (удаление стоп-слов, лемматизация).
- Использовать двунаправленный LSTM или механизм внимания.
- Поддержка многофразовых ответов.
- Перенос на GPU (добавить `model.to('cuda')` и `inputs.to('cuda')`).
- Сохранение словарей `word_to_index` и `index_to_word` между запусками.

## Лицензия

Проект распространяется под лицензией GNU GENERAL PUBLIC LICENSE. Подробности в файле `LICENSE`.
